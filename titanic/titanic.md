# 모델 학습 시 고려사항 가이드

 모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하고 있지 못한다면 결코 의미있지 않습니다.   
 코드를 짜는 시간보다 고민하는 데에 더 많은 시간을 할애하셨으면 합니다. 또 결과를 통해 증명하기보다 본인의 논리를 믿고 따르는 습관을 들이면 좋겠습니다. 예상과 다르다면 다시 학습해가면 됩니다.

 모든 부분에 힘을 주실 필요가 없습니다.   

--------

모델을 학습할 때는 다양한 요소를 고려해야 합니다. 이는 데이터의 전처리부터 모델의 선택과 평가에 이르기까지 여러 단계에 걸쳐 영향을 미칩니다. 아래는 주요한 요소들을 설명합니다.

1. 결측치 처리
> 🧞‍♀️ 시각화 등으로 결측치를 확인해주세요. 각 열의 결측치를 대체한 방법과 왜 그 방법을 사용했는지에 관하여 논리적으로 서술해주세요.    

cabin 컬럼 삭제    
: 891개의 데이터 중 train set에 결측치가 687개 있었기에 사용할 수 없는 데이터라고 판단. 또한 큰 의미를 찾을 수 없었음 방호수....

age 컬럼
: age는 사망에 영향을 미치는 요인일거라고 판단. 
age의 분포를 확인하고 평균/중위값 둘 중 하나를 골라서 결측치를 채우기로 결정.     
왜도, 첨도 확인 결과 : 왜도(Skewness): 0.38910778230082704
첨도(Kurtosis): 0.17827415364210353    
왜도가 0에 가까워 대칭적인 분포에 가깝다. 일반적으로 |왜도| < 0.5이면 대칭 분포로 간주할 수 있음.    
첨도도 0에 가까워 평균적인 중앙 집중적인 분포를 보인다.    
==> 평균값으로 결측치 처리     


2. 데이터 인코딩
범주형 변수는 모델이 이해할 수 있는 숫자 형태로 변환해야 합니다. 대표적인 방법으로는 Label Encoding(위계가 있는 경우)과 One-Hot Encoding(순서가 없는 경우)이 있습니다. 타겟 인코딩은 범주형 피처를 타겟 변수의 평균이나 비율로 인코딩하는 방법입니다. 타겟 변수가 특정 값일 확률을 사용하기도 합니다.

> 🧞‍♀️ 범주형 변수에 대해서 인코딩을 수행하셨다면 어떤 칼럼에 대해, 어떤 인코딩 방법을 사용하였는지 논리적으로 설명해주세요. (이때, 고려했던 인코딩 방법과 선택하지 않은 이유를 함께 제시해주세요.)

3. 데이터 스케일링

> 🧞‍♀️ 해당 데이터의 정규화 필요성에 대하여 논의해주세요. 해당 분포를 모델링에 적합한 형태로 변환하기 위해 사용한 스케일링 방식에 대해 설명해주세요.
> (ex. MinMax 스케일링은 이상치에 관하여 민감하므로, 그렇지 않은 ~ 방법을 사용했습니다.)

범주형 스케일링 의 경우 
- one-hot encoding : 스케일링 필요 X    
- label encoding : 스케일링 필요할 수도   

1. 정규화(Min-Max Scaling)
📌 특징   
- 데이터의 최소값을 0, 최대값을 1로 조정하는 방법.      
- 값이 0과 1 사이에 존재하도록 변환됨.    
- 이상치(outlier)에 민감해서 이상치가 있으면 비효율적.
- 거리가 중요한 알고리즘(KNN, K-means, SVM, 신경망 등)

2. 표준화(Standardization, Z-score Normalization)
📌 특징
- 평균을 0, 표준편차를 1로 변환하여 데이터를 정규분포 형태로 조정.    
- 값이 양수, 음수 모두 가능함.      
- 이상치에 비교적 덜 민감하지만, 너무 극단적인 이상치가 많다면 주의해야 함.
- 정규분포를 가정하는 알고리즘(선형 회귀, PCA 등)


Fare: 범위가 크고 이상치가 있는 경우 Min-Max를 쓰면 이상치 때문에 대부분의 값이 0 근처로 몰릴 가능성이 있음    
-> 로그변환+표준화 방법 사용
(Fare의 최소값: 0, 최대값: 512.33 → 범위가 너무 큼 -> 로그변환 후 표준화 진행)     
Age: 평균 29.7, 표준편차 14.5로 비교적 정규분포에 가까움 → 그냥 표준화




4. 데이터 왜도
왜도(skewness) 처리: 데이터가 비대칭적으로 분포되어 있을 때 로그 변환, 박스-콕스(Box-Cox) 변환 등을 사용해 왜도를 줄일 수 있습니다. 왜도가 크면 모델의 성능이 저하될 수 있습니다.

> 🧞‍♀️ 어떤 경우에 어떤 왜도 처리를 하는지 공부해보세요. 해당 데이터의 분포를 나타내는 시각화를 진행하고, 왜도를 수치로 표현해보세요.
타이타닉 데이터셋의 각 수치형 컬럼에는 왜도 처리가 필요한가요? 왜 그렇게 판단했나요?

5. 이상치(Outliers)
이상치 처리: 이상치는 모델에 부정적인 영향을 줄 수 있기 때문에 이를 식별하고 처리하는 것이 중요합니다. 이상치를 제거하거나, 다른 값으로 대체(예: 중앙값)하는 방법이 있습니다. 이상치가 반드시 잘못된 것은 아니므로 주의해야 합니다.

> 🧞‍♀️ 이상치를 처리하였나요? 어떤 기준으로 이상치를 판단하였나요?     

📌 이상치(Outlier)
- IQR 기준: 이상치가 전체 데이터의 5~10%를 넘으면 많다고 판단
- Z-score 기준: Z-score가 ±3을 넘는 데이터가 5~10%를 초과하면 많다고 판단
- Boxplot 시각화: 수염 밖의 점들이 너무 많으면 이상치가 많다고 해석 가능

📌 이상치 분석 결과      
-IQR 기준
Age: 1.23% (전체 데이터의 5% 미만 → 이상치가 많지 않음)
Fare: 13.02% (5~10% 기준을 초과 → 이상치가 많음!)     
-박스플랏 그림 해석
Age는 수염 밖에 점이 거의 없어서 이상치가 많지 않음.
Fare는 일부 큰 값(512.33 등)이 확연히 튀어나와 있음 → 이상치 영향이 큼!       
=> Age는 이상치 영향이 적으므로 그냥 표준화하면 됨. Fare는 IQR 기준으로 이상치가 많으므로, 로그 변환 후 표준화하는 것이 적절함!      

6. 피처 선택 및 생성
피처 선택(Feature Selection): 모델 성능을 개선하거나 과적합을 방지하기 위해 불필요한 피처를 제거합니다. 이를 위해 통계적 방법(예: p-value), 모델 기반 방법(예: L1 정규화), 또는 피처 중요도를 활용합니다.

피처 생성(Feature Engineering): 모델 성능을 높이기 위해 새로운 피처를 생성할 수 있습니다. 예를 들어, 두 피처를 곱하거나 나누어 새로운 피처를 만들 수 있습니다.

> 🧞‍♀️ 새로 만든 피쳐가 있다면 자랑해주세요.

> 🧞‍♀️ 다중공선성이 있다고 판단되는 지표가 있었나요? 왜 그렇게 생각하셨으며, 어떻게 처리하셨나요?

7. 데이터 분할
훈련/검증/테스트 데이터 분할: 데이터셋을 훈련, 검증, 테스트 세트로 나누어 모델의 성능을 평가합니다. 일반적으로 70-80%를 훈련 데이터로 사용하고, 나머지를 검증과 테스트 데이터로 사용합니다.

> 🧞‍♀️ 데이터 분할 방법 중 K-Fold Cross-Validation과 Stratified K-fold Cross Validation에 대해 공부해보세요. 최종적으로 어떤 방법을 사용했는지, 왜 사용했는지에 대해 서술해주세요.

 K-Fold Cross-Validation : 데이터 균형일 때          
Stratified K-fold Cross Validation : 데이터 불균형일 때       

0:1 비율이 대략 6:4 수준이므로 심각한 불균형은 아님      
일반 K-Fold도 가능하지만, Stratified K-Fold를 사용하면 더 안정적인 평가가 가능        
일반적인 K-Fold를 사용하면 한 Fold에 특정 클래스가 몰려 학습이 왜곡될 수 있음         
Stratified K-Fold를 사용하면 각 Fold에서도 0과 1의 비율을 유지할 수 있어, 모델이 더 안정적으로 학습됨

8. 모델 선택
모델 유형 선택: 데이터의 특성에 따라 적합한 모델을 선택해야 합니다. 예를 들어, 선형 데이터에는 선형 회귀, 비선형 데이터에는 트리 기반 모델 등이 효과적일 수 있습니다.

> 🧞‍♀️ 해당 데이터가 예측하고자 하는 값이 어떤 유형인지에 관련하여 모델 선정의 논리성을 증명해주세요. 또한, 차안으로 선택할 수 있는 모델이 있다면 추천해주세요.


+ 하이퍼파라미터 튜닝: 각 모델의 하이퍼파라미터를 최적화하여 성능을 극대화할 수 있습니다. 그리드 서치(Grid Search)나 랜덤 서치(Random Search) 등의 방법이 도모됩니다.

9. 모델 평가
평가 지표 선택: 회귀 문제에서는 MSE, MAE, R², 분류 문제에서는 정확도, 정밀도, 재현율, F1-score 등을 사용하여 모델 성능을 평가합니다.
교차 검증(Cross-Validation): 데이터를 여러 번 분할하여 모델을 평가하는 방법입니다. 이를 통해 모델의 일반화 성능을 더 잘 평가할 수 있습니다.

평가 지표의 종류에 대해 공부해보세요. 
- Accuracy → 클래스 비율이 균형 잡혔을 때 사용     
- Precision → FP(False Positive)가 치명적인 경우 (예: 스팸 필터)      
- Recall → FN(False Negative)가 치명적인 경우 (예: 암 진단)      
- F1-score → Precision과 Recall의 균형이 중요할 때 (예: 불균형 데이터)     
![hi](스크린샷%202025-03-15%20오후%207.11.09.png)


10. 과적합 방지
모델의 과적합을 방지하기 위한 여러 방법들이 있습니다.   
- 정규화(Regularization): L1, L2 정규화를 통해 모델의 복잡도를 조절하여 과적합을 방지합니다.   
- 드롭아웃(Dropout): 신경망에서 드롭아웃을 사용하여 과적합을 방지할 수 있습니다.   
- 얼리 스탑핑(Early Stopping): 검증 데이터의 성능이 더 이상 개선되지 않으면 훈련을 조기에 중지합니다.   

> 🧞‍♀️ 과적합 방지를 위해 도입한 방법이 있나요? 그 방법의 원리와 장점은 무엇인가요?

---
*출처: 4기 교육팀장님*
